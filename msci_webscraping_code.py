# -*- coding: utf-8 -*-
"""MSCI Webscraping Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zrQr2FudyV4qDngLTWLTEN5ilWX5er-0
"""

# code to install selenium
!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin
import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
webd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)

import requests
import json
from bs4 import BeautifulSoup
import time
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.keys import Keys

def change_site (company):

  webd.get('https://www.msci.com/our-solutions/esg-investing/esg-ratings/esg-ratings-corporate-search-tool')
  search = webd.find_element_by_id('_esgratingsprofile_keywords')
  search.clear()
  search.send_keys(company)
  time.sleep(2)
  search.send_keys(Keys.DOWN)
  search.send_keys(Keys.RETURN)
  new_url = webd.current_url

  return new_url


link = change_site('Dell')
print(link)

url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'

  response = requests.get(url)
  data = response.text
  soup = BeautifulSoup(data, 'html')

  table = soup.find_all('table')[0]

  df = pd.read_html(str(table))[0]
 
df

def get_data(link):
  time.sleep(2)
  page_source = webd.page_source
  soup = BeautifulSoup(page_source, 'html')
  webd.get(link)
  name = soup.find('div', class_= 'header-company-title').text
  ticker = soup.find('div', class_= 'header-company-ticker').text
  change = soup.find('div', class_= 'esg-rating-paragraph esg-rating-paragraph-hist col-lg-6').text
  comp = soup.find('div', class_= 'esg-rating-paragraph esg-rating-paragraph-distr col-lg-6').text
  industry = soup.find('div', class_= 'header-esg-industry').text
  country = soup.find('div', class_= 'header-country').text
  rating = soup.find_all('text', x ='5', style = 'font-size:14px;;font-weight:bold;color:#FFFFFF;fill:#FFFFFF;', y = '19',)
  rating = rating[-1]
  rating=rating.text

  names =[]
  name = name.strip('\n\t\t\t')
  names.append(name)

  ratings =[]
  ratings.append(rating)

  tickers = []
  ticker = ticker.strip('\n\t\t\t')
  tickers.append(ticker)

  changes =[]
  change = change.strip('\n\t\t\t')
  changes.append(change)

  comps =[]
  com =''
  if 'leader' in comp:
    com = 'Leader'
  elif 'laggard' in comp:
    com = 'Laggard'
  else:
    com = 'Average'
  comps.append(com)

  industries =[]
  industry = industry.strip('\n\t\t\t')
  industry = industry.strip('Industry:')
  industries.append(industry)

  countries =[]
  country = country.strip('\n\t\t\t')
  country = country.strip('Country/Region:')
  countries.append(country)


  df = pd.DataFrame()
  df['Name'] = names
  df['Ticker'] = tickers
  df['Activity'] = changes
  df['Comparison'] = comps
  df['Industry'] = industries
  df['Country'] = countries
  df['Rating'] = ratings
  return df

get_data('https://www.msci.com/our-solutions/esg-investing/esg-ratings/esg-ratings-corporate-search-tool/issuer/hewlett-packard-enterprise-company/IID000000002744642')

links = []
#companies = ['3M', 'Abbot', 'Abbvie']
companies = []
company_list = df['Security'].tolist()
company_list3 = company_list[0:505]

for i in company_list3:
      companies.append(i)
counter1 = 0
for company in companies: 
  link = change_site(company)
  links.append(link)
  index1 = str(counter1+1)
  print ((index1)+'.)', company + ': link found')
  counter1 += 1

#print(company_list3)
#print(links)

final_list = []

counter = 0
for x in links:
 while True:
   try: 
    data = get_data(x)
    final_list.append(data)
    index = str(counter+1)
    print ((index)+'.)', company_list3[counter]+': Success!')
    counter += 1
    break
   except AttributeError:
    print(company_list3[counter]+': Failed: Trying Again')
    pass
  
    
ESG = pd.concat(final_list)
ESG.sort_values(['Name'])

# Commented out IPython magic to ensure Python compatibility.
import os
import sqlalchemy
ESG.to_csv('MSCI-505.csv')
# Install the SQLAlchemy library if it is not installed
!sudo apt-get install python3-dev libmysqlclient-dev > /dev/null
!pip install mysqlclient > /dev/null
!sudo pip3 install -U sql_magic > /dev/null
!pip install psycopg2-binary > /dev/null

from sqlalchemy import create_engine

conn_string = 'mysql://{user}:{password}@{host}:{port}/{db}?charset=utf8'.format(
    user='Apollo', 
    password='YB5/OcxMh10=', 
    host = 'jsedocc7.scrc.nyu.edu', 
    port     = 3306, 
    encoding = 'utf-8',
    db = "ApolloDB"
)

engine = create_engine(conn_string)

# Prepare sql_magic library that enable to query to database easily.
# %reload_ext sql_magic
# %config SQL.conn_name = 'engine'

ESG.to_sql('ESG 505', con = engine)

pd.read_sql_table('ESG 505', con = engine)